from datetime import datetime
from pathlib import Path
from typing import List, Dict


def generate_health_report(results: List[Dict], repo_path: str) -> None:
    """
    Generate a health report in Markdown format based on analysis results.
    
    Args:
        results: List of complexity issues found during analysis
        repo_path: Path to the repository root
    """
    repo_path = Path(repo_path)
    reports_dir = repo_path / ".evolver" / "reports"
    
    # Ensure the reports directory exists
    reports_dir.mkdir(parents=True, exist_ok=True)
    
    report_path = reports_dir / "HEALTH_REPORT.md"
    
    # Generate the report content
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    content = f"""# 🏥 EvolverAgent Health Report

**Generated on:** {timestamp}  
**Repository:** Primoia Monorepo  
**Analyzer:** EvolverAgent MVP

## 📊 Summary

Total complexity issues found: **{len(results)}**

"""
    
    if not results:
        content += """## ✅ No Issues Found

Great news! No functions or methods were found with cyclomatic complexity exceeding 10.
The codebase appears to be well-structured from a complexity perspective.

"""
    else:
        # Group results by file for better organization
        files_with_issues = {}
        for issue in results:
            file_path = issue['file']
            if file_path not in files_with_issues:
                files_with_issues[file_path] = []
            files_with_issues[file_path].append(issue)
        
        content += f"""## ⚠️ Complexity Issues

Found {len(results)} functions/methods with cyclomatic complexity > 10 across {len(files_with_issues)} files.

### 📋 Issues by File

"""
        
        # Sort files by number of issues (descending)
        sorted_files = sorted(files_with_issues.items(), 
                            key=lambda x: len(x[1]), reverse=True)
        
        for file_path, file_issues in sorted_files:
            content += f"#### 📁 `{file_path}`\n\n"
            content += f"Issues found: **{len(file_issues)}**\n\n"
            
            # Sort issues by complexity (descending)
            sorted_issues = sorted(file_issues, 
                                 key=lambda x: x['complexity'], reverse=True)
            
            for issue in sorted_issues:
                complexity_level = get_complexity_level(issue['complexity'])
                content += f"- **{issue['function']}** (Line {issue['line']}) - "
                content += f"Complexity: **{issue['complexity']}** {complexity_level}\n"
            
            content += "\n"
    
    # Add recommendations section
    content += """## 🔧 Recommendations

### High Priority
- Functions with complexity > 15 should be refactored immediately
- Consider breaking down complex functions into smaller, focused methods

### Medium Priority  
- Functions with complexity 11-15 should be reviewed and potentially simplified
- Add unit tests for complex functions to ensure refactoring safety

### Best Practices
- Aim for cyclomatic complexity < 10 for all functions
- Use early returns to reduce nesting levels
- Extract complex conditional logic into separate methods
- Consider using design patterns to simplify complex workflows

## 📈 Next Steps

1. **Priority Refactoring**: Address the highest complexity functions first
2. **Code Review**: Have team members review complex functions
3. **Testing**: Ensure adequate test coverage before refactoring
4. **Monitoring**: Run EvolverAgent regularly to track improvements

---
*This report was automatically generated by EvolverAgent MVP*
"""
    
    # Write the report to file
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"Health report generated: {report_path}")


def get_complexity_level(complexity: int) -> str:
    """
    Get a visual indicator for complexity level.
    
    Args:
        complexity: The cyclomatic complexity value
        
    Returns:
        String with emoji indicator for complexity level
    """
    if complexity >= 20:
        return "🔴 Critical"
    elif complexity >= 15:
        return "🟡 High"
    elif complexity >= 11:
        return "🟠 Medium"
    else:
        return "🟢 Low"


def generate_summary_stats(results: List[Dict]) -> Dict:
    """
    Generate summary statistics from analysis results.
    
    Args:
        results: List of complexity issues
        
    Returns:
        Dictionary with summary statistics
    """
    if not results:
        return {
            'total_issues': 0,
            'average_complexity': 0,
            'max_complexity': 0,
            'files_affected': 0
        }
    
    complexities = [issue['complexity'] for issue in results]
    files_affected = len(set(issue['file'] for issue in results))
    
    return {
        'total_issues': len(results),
        'average_complexity': round(sum(complexities) / len(complexities), 2),
        'max_complexity': max(complexities),
        'files_affected': files_affected
    }